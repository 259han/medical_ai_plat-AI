model:
  max_length: 512
  device: "auto"
  generation_config:
    max_new_tokens: 200
    do_sample: true
    temperature: 0.7
    top_k: 50
    top_p: 0.95
    repetition_penalty: 1.1