#!/usr/bin/env python3
"""
Flask API æœåŠ¡ï¼Œç”¨äºèƒ¸éƒ¨ X å…‰å›¾ç‰‡çš„ç–¾ç—…é¢„æµ‹å’Œç—…ç¶å®šä½çƒ­åŠ›å›¾ç”Ÿæˆ
æ”¯æŒ GradCAMã€GradCAM++ å’Œ ScoreCAM
"""

import sys
import os
import uuid
import logging
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
from PIL import Image
import cv2
from flask import Flask, request, jsonify, send_file
from werkzeug.utils import secure_filename
from pathlib import Path
import torchvision.transforms as transforms

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# CAM åŸºç±»
class CAMBase:
    def __init__(self, model, target_layers, use_cuda=False):
        self.model = model.eval()
        self.target_layers = target_layers
        self.use_cuda = use_cuda
        self.device = torch.device("cuda" if use_cuda and torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        self.gradients = []
        self.activations = []
        self._register_hooks()

    def _register_hooks(self):
        def forward_hook(module, input, output):
            self.activations.append(output)
        def backward_hook(module, grad_in, grad_out):
            self.gradients.append(grad_out[0])
        for layer in self.target_layers:
            layer.register_forward_hook(forward_hook)
            layer.register_backward_hook(backward_hook)

    def __call__(self, input_tensor, targets=None):
        raise NotImplementedError

    def _get_activations_gradients(self, input_tensor):
        self.gradients = []
        self.activations = []
        output = self.model(input_tensor)
        return output

# GradCAM ç±» - æ”¹è¿›ç‰ˆæœ¬
class GradCAM(CAMBase):
    def __call__(self, input_tensor, targets=None):
        input_tensor = input_tensor.to(self.device)
        output = self._get_activations_gradients(input_tensor)
        if targets is not None:
            self.model.zero_grad()
            target_score = output[0, targets].sum()
            target_score.backward()
        
        activations = self.activations[0].detach()
        gradients = self.gradients[0].detach()
        
        # ä½¿ç”¨ReLUç¡®ä¿æ¢¯åº¦ä¸ºæ­£å€¼
        gradients = F.relu(gradients)
        
        # è®¡ç®—æƒé‡
        weights = torch.mean(gradients, dim=(2, 3))
        
        # åˆ›å»ºCAM
        cam = torch.zeros(activations.shape[2:], device=self.device)
        for i, w in enumerate(weights[0]):
            cam += w * activations[0, i]
        
        # åå¤„ç†ï¼šç¡®ä¿æ•°å€¼ç¨³å®šæ€§
        cam = F.relu(cam)
        cam_min = cam.min()
        cam_max = cam.max()
        if cam_max > cam_min:
            cam = (cam - cam_min) / (cam_max - cam_min + 1e-8)
        
        return cam.cpu().numpy()[None, :]

# GradCAM++ ç±» - æ”¹è¿›ç‰ˆæœ¬
class GradCAMPlusPlus(CAMBase):
    def __call__(self, input_tensor, targets=None):
        input_tensor = input_tensor.to(self.device)
        output = self._get_activations_gradients(input_tensor)
        if targets is not None:
            self.model.zero_grad()
            target_score = output[0, targets].sum()
            target_score.backward()
        
        activations = self.activations[0].detach()
        gradients = self.gradients[0].detach()
        
        # è®¡ç®—alphaæƒé‡ï¼ˆGradCAM++çš„æ ¸å¿ƒï¼‰
        alpha_num = gradients ** 2
        alpha_denom = 2 * gradients ** 2 + torch.sum(activations * gradients ** 3, dim=(2, 3), keepdim=True)
        alpha = alpha_num / (alpha_denom + 1e-8)
        
        # è®¡ç®—æƒé‡
        weights = torch.sum(alpha * F.relu(gradients), dim=(2, 3))
        
        # åˆ›å»ºCAM
        cam = torch.zeros(activations.shape[2:], device=self.device)
        for i, w in enumerate(weights[0]):
            cam += w * activations[0, i]
        
        # åå¤„ç†ï¼šç¡®ä¿æ•°å€¼ç¨³å®šæ€§
        cam = F.relu(cam)
        cam_min = cam.min()
        cam_max = cam.max()
        if cam_max > cam_min:
            cam = (cam - cam_min) / (cam_max - cam_min + 1e-8)
        
        return cam.cpu().numpy()[None, :]

# ScoreCAM ç±» - æ”¹è¿›ç‰ˆæœ¬
class ScoreCAM(CAMBase):
    def __call__(self, input_tensor, targets=None):
        input_tensor = input_tensor.to(self.device)
        batch_size, _, height, width = input_tensor.size()
        
        # è·å–æ¿€æ´»å›¾
        with torch.no_grad():
            output = self._get_activations_gradients(input_tensor)
            activations = self.activations[0].detach()
        
        # ä½¿ç”¨ReLUç¡®ä¿æ¿€æ´»å›¾ä¸ºæ­£å€¼ï¼Œå¹¶æ ‡å‡†åŒ–
        activations = F.relu(activations)
        
        # è®¡ç®—æ¯ä¸ªé€šé“çš„é‡è¦æ€§åˆ†æ•°ï¼ˆåŸºäºæ¿€æ´»å¼ºåº¦ï¼‰
        channel_importance = torch.mean(activations.view(activations.size(1), -1), dim=1)
        
        # é€‰æ‹©å‰kä¸ªæœ€é‡è¦çš„é€šé“ä»¥æé«˜æ•ˆç‡
        k = min(64, activations.size(1))  # æœ€å¤šé€‰æ‹©64ä¸ªé€šé“
        _, top_k_indices = torch.topk(channel_importance, k)
        
        # åˆ›å»ºCAM
        cam = torch.zeros((height, width), device=self.device)
        
        with torch.no_grad():
            for i in top_k_indices:
                # è·å–å•ä¸ªé€šé“çš„æ¿€æ´»å›¾
                activation = activations[:, i:i+1, :, :]
                
                # ä¸Šé‡‡æ ·åˆ°è¾“å…¥å°ºå¯¸
                upsampled = F.interpolate(
                    activation,
                    size=(height, width),
                    mode='bilinear',
                    align_corners=False
                )
                
                # æ”¹è¿›çš„å½’ä¸€åŒ–ï¼šä½¿ç”¨softmax-likeå½’ä¸€åŒ–
                upsampled_flat = upsampled.view(upsampled.size(0), -1)
                upsampled_norm = F.softmax(upsampled_flat, dim=1).view_as(upsampled)
                
                # åˆ›å»ºæ©ç è¾“å…¥ - ä½¿ç”¨æ›´åˆç†çš„æ©ç æ–¹å¼
                masked_input = input_tensor * upsampled_norm
                
                # å‰å‘ä¼ æ’­
                output = self.model(masked_input)
                if targets is not None:
                    score = output[0, targets]
                else:
                    score = output[0].max()
                
                # ç´¯åŠ åˆ°CAMï¼Œä½¿ç”¨é€šé“é‡è¦æ€§ä½œä¸ºæƒé‡
                cam += score * upsampled_norm[0, 0] * channel_importance[i]
        
        # åå¤„ç†ï¼šç¡®ä¿æ•°å€¼ç¨³å®šæ€§
        cam = F.relu(cam)
        cam_min = cam.min()
        cam_max = cam.max()
        if cam_max > cam_min:
            cam = (cam - cam_min) / (cam_max - cam_min + 1e-8)
        
        return cam.cpu().numpy()[None, :]

# æ¨¡å‹ç±»
class DenseNet121(nn.Module):
    def __init__(self, num_classes=14, pretrained=False):
        super(DenseNet121, self).__init__()
        if pretrained:
            self.densenet = models.densenet121(pretrained=pretrained)
        else:
            self.densenet = models.densenet121(pretrained=False)
        num_ftrs = self.densenet.classifier.in_features
        self.densenet.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_ftrs, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        return self.densenet(x)

# é¢„æµ‹ç±»
class Predictor:
    def __init__(self, model, config):
        self.config = config
        self.model = model
        self.device = torch.device(self.config.DEVICE)
        self.model.to(self.device)
        self.model.eval()
        self.optimal_thresholds = self._load_optimal_thresholds()

    def _load_optimal_thresholds(self):
        threshold_path = os.path.join(self.config.CHECKPOINT_DIR, 'optimal_thresholds.pth')
        if os.path.exists(threshold_path):
            thresholds = torch.load(threshold_path, map_location='cpu')
            
            if isinstance(thresholds, list) or isinstance(thresholds, np.ndarray):
                logger.info(f"âœ… æˆåŠŸåŠ è½½é˜ˆå€¼: {thresholds}")
                return thresholds
            elif isinstance(thresholds, dict) and 'Optimal_Threshold' in thresholds:
                logger.info(f"âœ… æˆåŠŸåŠ è½½é˜ˆå€¼: {thresholds['Optimal_Threshold']}")
                return thresholds['Optimal_Threshold']
            else:
                logger.warning(f"Invalid format in {threshold_path}, using default threshold 0.5")
                return [0.5] * self.config.NUM_CLASSES
        else:
            logger.warning(f"{threshold_path} not found, using default threshold 0.5")
            return [0.5] * self.config.NUM_CLASSES

    def predict_single_image(self, image_path, transform):
        image = Image.open(image_path).convert('RGB')
        image = transform(image).unsqueeze(0)
        image = image.to(self.device)
        with torch.no_grad():
            output = self.model(image)
            probabilities = torch.sigmoid(output)
            predictions = torch.zeros_like(probabilities)
            for i, threshold in enumerate(self.optimal_thresholds):
                predictions[:, i] = (probabilities[:, i] > threshold).float()
        return predictions.cpu().numpy()[0], probabilities.cpu().numpy()[0]

# ä¸»æœåŠ¡ç±»
class ChestXrayService:
    def __init__(self, config=None):
        if config is None:
            from config import Config
            self.config = Config()
        else:
            self.config = config
            
        self.UPLOAD_FOLDER = str(self.config.UPLOAD_DIR)
        os.makedirs(self.UPLOAD_FOLDER, exist_ok=True)
        os.makedirs(str(self.config.RESULT_DIR), exist_ok=True)
        self.ALLOWED_EXTENSIONS = self.config.ALLOWED_EXTENSIONS
        try:
            self.model = DenseNet121(num_classes=self.config.NUM_CLASSES, pretrained=True)
            checkpoint_path = os.path.join(str(self.config.CHECKPOINT_DIR), 'best_model.pth')
            if not os.path.exists(checkpoint_path):
                raise FileNotFoundError(f"Checkpoint not found at {checkpoint_path}")
            
            checkpoint = torch.load(checkpoint_path, map_location=self.config.DEVICE)
            
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.to(self.config.DEVICE)
            self.model.eval()
            logger.info("âœ… Model loaded successfully")
            logger.info(f"ğŸ“‹ æ¨¡å‹é…ç½®: num_classes={self.config.NUM_CLASSES}, pretrained=True")
        except Exception as e:
            logger.error(f"âŒ Failed to load model: {e}")
            raise RuntimeError("Model initialization failed")
        self.predictor = Predictor(self.model, self.config)
        self.target_layer = self.model.densenet.features.denseblock4

    def allowed_file(self, filename):
        return '.' in filename and filename.rsplit('.', 1)[1].lower() in self.ALLOWED_EXTENSIONS

    def get_transforms(self, is_training=False):
        return transforms.Compose([
            transforms.Resize((512, 512)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

    def generate_heatmap(self, image_tensor, class_idx, cam_method):
        cam_classes = {
            'gradcam': GradCAM,
            'gradcam++': GradCAMPlusPlus,
            'scorecam': ScoreCAM
        }
        if cam_method not in cam_classes:
            raise ValueError(f"Unsupported CAM method: {cam_method}")
        cam = cam_classes[cam_method](self.model, [self.target_layer], use_cuda=(self.config.DEVICE == 'cuda'))
        heatmap = cam(image_tensor, targets=class_idx)
        return heatmap[0]

    def predict(self, file, cam_method='gradcam', user_id: str = None):
        if file.filename == '' or not self.allowed_file(file.filename):
            raise ValueError('Invalid file format. Only PNG, JPG, JPEG allowed')
        
        filename = secure_filename(f"{uuid.uuid4()}_{file.filename}")
        file_path = os.path.join(self.UPLOAD_FOLDER, filename)
        file.save(file_path)
        logger.info(f"ğŸ“ ä¸´æ—¶æ–‡ä»¶å·²ä¿å­˜: {file_path}")
        
        try:
            from utils.redis_manager import get_redis_manager
            redis_mgr = get_redis_manager()
            
            # ç”Ÿæˆç¼“å­˜é”®ï¼ˆåŸºäºæ–‡ä»¶å†…å®¹å’Œå‚æ•°ï¼‰
            import hashlib
            with open(file_path, 'rb') as f:
                file_hash = hashlib.md5(f.read()).hexdigest()
            cache_key = f"chest_xray:{file_hash}:{cam_method}"
            
            cached_result = redis_mgr.get_cache(cache_key)
            if cached_result:
                logger.info(f"âœ… èƒ¸éƒ¨Xå…‰é¢„æµ‹ç¼“å­˜å‘½ä¸­: {filename}")
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(file_path)
                return cached_result
        except Exception as e:
            logger.warning(f"ç¼“å­˜æ£€æŸ¥å¤±è´¥: {e}")
        
        # è¯»å–åŸå§‹å›¾ç‰‡å¹¶ä¿å­˜å°ºå¯¸ä¿¡æ¯
        original_image = Image.open(file_path).convert('RGB')
        original_size = original_image.size  # (width, height)
        original_np = np.array(original_image)
        
        # è®°å½•è°ƒè¯•ä¿¡æ¯
        logger.info(f"å¤„ç†å›¾ç‰‡: {filename}")
        logger.info(f"åŸå§‹å°ºå¯¸: {original_size}")
        logger.info(f"åŸå§‹æ•°ç»„å½¢çŠ¶: {original_np.shape}")
        
        # åº”ç”¨å˜æ¢å¾—åˆ°æ¨¡å‹è¾“å…¥
        transform = self.get_transforms(is_training=False)
        image_tensor = transform(original_image).unsqueeze(0).to(self.config.DEVICE)
        
        logger.info(f"æ¨¡å‹è¾“å…¥å¼ é‡å½¢çŠ¶: {image_tensor.shape}")
        
        # è¿›è¡Œé¢„æµ‹
        with torch.no_grad():
            output = self.model(image_tensor)
            probabilities = torch.sigmoid(output)
            predictions = torch.zeros_like(probabilities)
            for i, threshold in enumerate(self.predictor.optimal_thresholds):
                predictions[:, i] = (probabilities[:, i] > threshold).float()
        
        pred_labels = predictions.cpu().numpy()[0]
        pred_probs = probabilities.cpu().numpy()[0]
        
        # è¯¦ç»†è®°å½•é¢„æµ‹ç»“æœ
        logger.info("=" * 60)
        logger.info("ğŸ” è¯¦ç»†é¢„æµ‹ç»“æœåˆ†æ")
        logger.info("=" * 60)
        logger.info(f"æ¨¡å‹è¾“å‡ºåŸå§‹å€¼èŒƒå›´: [{output.min().item():.4f}, {output.max().item():.4f}]")
        logger.info(f"Sigmoidåæ¦‚ç‡å€¼èŒƒå›´: [{pred_probs.min():.4f}, {pred_probs.max():.4f}]")
        logger.info(f"ä½¿ç”¨çš„é˜ˆå€¼: {self.predictor.optimal_thresholds}")
        logger.info("")
        
        # è®°å½•æ¯ä¸ªç–¾ç—…çš„é¢„æµ‹ç»“æœ
        logger.info("ğŸ“Š å„ç–¾ç—…é¢„æµ‹è¯¦æƒ…:")
        for i, (disease, prob, pred, threshold) in enumerate(zip(
            self.config.DISEASE_LABELS, pred_probs, pred_labels, self.predictor.optimal_thresholds
        )):
            status = "âœ… é˜³æ€§" if pred == 1 else "âŒ é˜´æ€§"
            logger.info(f"  {i:2d}. {disease:20s}: æ¦‚ç‡={prob:.4f}, é˜ˆå€¼={threshold:.4f}, é¢„æµ‹={status}")
        
        # é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«ç”Ÿæˆçƒ­åŠ›å›¾
        class_idx = np.argmax(pred_probs)
        max_prob = pred_probs[class_idx]
        max_disease = self.config.DISEASE_LABELS[class_idx]
        logger.info("")
        logger.info(f"ğŸ¯ é€‰æ‹©ç”¨äºçƒ­åŠ›å›¾çš„ç±»åˆ«: {class_idx} ({max_disease}), æ¦‚ç‡: {max_prob:.4f}")
        
        # è®°å½•é˜³æ€§é¢„æµ‹çš„ç–¾ç—…
        positive_diseases = [self.config.DISEASE_LABELS[i] for i, pred in enumerate(pred_labels) if pred == 1]
        logger.info(f"ğŸ” æœ€ç»ˆé˜³æ€§é¢„æµ‹ç–¾ç—…: {positive_diseases}")
        logger.info("=" * 60)
        
        # ç”Ÿæˆçƒ­åŠ›å›¾
        logger.info(f"å¼€å§‹ç”Ÿæˆçƒ­åŠ›å›¾ï¼Œæ–¹æ³•: {cam_method}")
        heatmap = self.generate_heatmap(image_tensor, class_idx, cam_method)
        logger.info(f"çƒ­åŠ›å›¾å½¢çŠ¶: {heatmap.shape}, å€¼èŒƒå›´: [{heatmap.min():.4f}, {heatmap.max():.4f}]")
        
        # æ”¹è¿›çš„çƒ­åŠ›å›¾resizeæ–¹æ³•
        # ä½¿ç”¨åŒçº¿æ€§æ’å€¼è€Œä¸æ˜¯æœ€è¿‘é‚»æ’å€¼ï¼Œä¿æŒçƒ­åŠ›å›¾çš„å¹³æ»‘æ€§
        heatmap_resized = cv2.resize(heatmap, (original_size[0], original_size[1]), 
                                   interpolation=cv2.INTER_LINEAR)
        
        logger.info(f"è°ƒæ•´åçƒ­åŠ›å›¾å½¢çŠ¶: {heatmap_resized.shape}")
        
        # ç¡®ä¿çƒ­åŠ›å›¾å€¼åœ¨åˆç†èŒƒå›´å†…
        heatmap_resized = np.clip(heatmap_resized, 0, 1)
        logger.info(f"è£å‰ªåçƒ­åŠ›å›¾å€¼èŒƒå›´: [{heatmap_resized.min():.4f}, {heatmap_resized.max():.4f}]")
        
        # è½¬æ¢ä¸º8ä½å›¾åƒç”¨äºå¯è§†åŒ–
        heatmap_uint8 = np.uint8(255 * heatmap_resized)
        heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
        
        # ç¡®ä¿åŸå§‹å›¾ç‰‡æ˜¯BGRæ ¼å¼ç”¨äºå åŠ 
        if len(original_np.shape) == 3 and original_np.shape[2] == 3:
            # å¦‚æœæ˜¯RGBæ ¼å¼ï¼Œè½¬æ¢ä¸ºBGR
            original_bgr = cv2.cvtColor(original_np, cv2.COLOR_RGB2BGR)
        else:
            original_bgr = original_np
        
        # å åŠ çƒ­åŠ›å›¾åˆ°åŸå›¾
        superimposed_img = heatmap_colored * 0.3 + original_bgr * 0.7
        superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)
        
        # ä¿å­˜ç»“æœ
        heatmap_filename = f'heatmap_{cam_method}_{filename}'
        superimposed_filename = f'superimposed_{cam_method}_{filename}'
        heatmap_path = os.path.join(self.config.RESULT_DIR, heatmap_filename)
        superimposed_path = os.path.join(self.config.RESULT_DIR, superimposed_filename)
        
        # ä¿å­˜çƒ­åŠ›å›¾ï¼ˆè½¬æ¢ä¸ºRGBæ ¼å¼ï¼‰
        heatmap_rgb = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)
        Image.fromarray(heatmap_rgb).save(heatmap_path)
        
        # ä¿å­˜å åŠ å›¾ï¼ˆè½¬æ¢ä¸ºRGBæ ¼å¼ï¼‰
        superimposed_rgb = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)
        Image.fromarray(superimposed_rgb).save(superimposed_path)
        
        logger.info(f"ä¿å­˜çƒ­åŠ›å›¾: {heatmap_path}")
        logger.info(f"ä¿å­˜å åŠ å›¾: {superimposed_path}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.remove(file_path)
        logger.info(f"ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†: {file_path}")
        
        # è¿”å›ç»“æœ
        predictions = {}
        for i in range(self.config.NUM_CLASSES):
            predictions[self.config.DISEASE_LABELS[i]] = {
                'positive': bool(pred_labels[i]),
                'probability': float(pred_probs[i])
            }
        
        results = {
            'predictions': predictions,
            'heatmap_path': heatmap_filename,
            'superimposed_path': superimposed_filename,
            'cam_method': cam_method,
            'original_size': original_size,
            'model_input_size': (512, 512)  # ä¸chestxraysä¿æŒä¸€è‡´
        }
        
        # æ·»åŠ æ”¹è¿›çš„CAMæ–¹æ³•è¯´æ˜
        logger.info("ğŸ¯ ä½¿ç”¨çš„æ”¹è¿›CAMæ–¹æ³•:")
        if cam_method == 'gradcam':
            logger.info("  - GradCAM: ä½¿ç”¨ReLUç¡®ä¿æ¢¯åº¦ä¸ºæ­£å€¼ï¼Œæ”¹è¿›æ•°å€¼ç¨³å®šæ€§")
        elif cam_method == 'gradcam++':
            logger.info("  - GradCAM++: ä½¿ç”¨alphaæƒé‡è®¡ç®—ï¼Œæ”¹è¿›å®šä½ç²¾åº¦")
        elif cam_method == 'scorecam':
            logger.info("  - ScoreCAM: é€‰æ‹©å‰64ä¸ªé‡è¦é€šé“ï¼Œä½¿ç”¨softmaxå½’ä¸€åŒ–ï¼Œæé«˜æ•ˆç‡")
        
        # ç¼“å­˜ç»“æœ
        try:
            if 'redis_mgr' in locals():
                redis_mgr.set_cache(cache_key, results, cache_type="prediction")
                logger.info(f"âœ… èƒ¸éƒ¨Xå…‰é¢„æµ‹ç»“æœå·²ç¼“å­˜: {filename}")
        except Exception as e:
            logger.warning(f"ç¼“å­˜èƒ¸éƒ¨Xå…‰é¢„æµ‹ç»“æœå¤±è´¥: {e}")
        
        return results

    def get_image(self, image_path):
        filename = os.path.basename(image_path)
        full_path = os.path.join(str(self.config.RESULT_DIR), filename)
        
        logger.info(f"æœåŠ¡è·å–å›¾ç‰‡ - è¾“å…¥è·¯å¾„: {image_path}, æ–‡ä»¶å: {filename}, å®Œæ•´è·¯å¾„: {full_path}")
        
        if not os.path.exists(full_path):
            logger.error(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
            raise FileNotFoundError(f'Image not found: {filename}')
        
        return full_path

# Flask åº”ç”¨
app = Flask(__name__)
service = ChestXrayService()

@app.route('/predict', methods=['POST'])
def predict():
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400
        file = request.files['file']
        cam_method = request.form.get('cam_method', 'gradcam')
        if cam_method not in ['gradcam', 'gradcam++', 'scorecam']:
            return jsonify({'error': 'Invalid CAM method'}), 400
        results = service.predict(file, cam_method)
        return jsonify(results)
    except Exception as e:
        logger.error(f"Error in predict: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/get_image/<path:image_path>', methods=['GET'])
def get_image(image_path):
    try:
        full_path = service.get_image(image_path)
        return send_file(full_path, mimetype='image/png')
    except Exception as e:
        logger.error(f"Error in get_image: {e}")
        return jsonify({'error': str(e)}), 404

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)